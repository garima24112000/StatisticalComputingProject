---
title: "computingProject"
output: pdf_document
date: "2025-04-03"
---

```{r}
# Load required libraries
library(dplyr)
library(tidyr)
library(caret)
library(zoo)

# Load the dataset
data <- read.csv("visualizing_global_co2_data.csv")



# 1. Filter the data to include only rows where the year is greater than or equal to 1980
data <- data %>% filter(year >= 1980)
nrow(data)
ncol(data)
sum(is.na(data))
# Alternatively, drop columns with too many missing values (e.g., more than 50% missing)
threshold <- 0.5 * nrow(data)
data <- data %>% select(which(colSums(is.na(data)) < threshold))
nrow(data)
ncol(data)
# 2. Handle Missing Values
# Impute missing values for numerical columns with the mean
numerical_columns <- sapply(data, is.numeric)
data[numerical_columns] <- lapply(data[numerical_columns], function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))
nrow(data)

# 3. Remove Duplicate Entries
data <- distinct(data)
nrow(data)
ncol(data)
# 4. Data Type Conversion
# Ensure 'year' is an integer
data$year <- as.integer(data$year)
sum(is.na(data))
# Convert 'population' to numeric, handling any non-numeric entries
data$population <- as.numeric(data$population)

# 5. Handling Categorical Data (optional)
# If 'country' and 'iso_code' need encoding, you can use one-hot encoding
data <- data %>% mutate(country = factor(country)) # Convert country to factor for encoding if necessary
data <- cbind(data, model.matrix(~ country - 1, data)) # One-hot encoding for country (if needed)
nrow(data)
# 6. Feature Scaling (standardization)
numerical_columns <- names(data)[sapply(data, is.numeric)]
data[numerical_columns] <- scale(data[numerical_columns])

# 7. Outlier Detection
# Example: Remove rows where 'co2' is above a certain threshold (adjust the threshold as needed)
data <- data %>% filter(co2 < 10000)

# 8. Create New Features (example: Year-over-year change in CO2)
data$co2_growth <- c(NA, diff(data$co2) / head(data$co2, -1)) # Year-over-year percentage growth

# 9. Check for Multicollinearity (optional)
correlation_matrix <- cor(data[numerical_columns], use = "complete.obs")
print("Correlation Matrix:")
print(correlation_matrix)

# 1. Interpolation for Time Series Data (Linear or Spline)
# Interpolate missing values in the 'co2' column using linear interpolation
data$co2 <- zoo(data$co2, order.by = data$year)
data$co2 <- na.approx(data$co2)  # Linear interpolation

# Alternatively, for spline interpolation, use this:
# data$co2 <- na.spline(data$co2)  # Uncomment for spline interpolation

# 2. Mode Imputation for Categorical Data
# Impute missing 'country' values with the mode
get_mode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Impute missing 'country' values with the mode
data$country[is.na(data$country)] <- get_mode(data$country)
sum(is.na(data))
# 10. Data Splitting (optional)
set.seed(42)
trainIndex <- createDataPartition(data$co2, p = 0.7, list = FALSE) # 70% train, 30% test
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]


print("Preprocessed Data:")
print(head(data))


```

```{r}

# Load required libraries
library(dplyr)
library(tidyr)
library(caret)
library(zoo)

# Load the dataset
data <- read.csv("visualizing_global_co2_data.csv")

# 1. Filter the data to include only rows where the year is greater than or equal to 1980
data <- data %>% filter(year >= 1980)
data <- data %>% select(-iso_code)
# 2. Drop columns with too many missing values (e.g., more than 50% missing)
threshold <- 0.5 * nrow(data)
data <- data %>% select(which(colSums(is.na(data)) < threshold))

# 3. Handle Missing Values
# Impute missing values for numerical columns with the mean
numerical_columns <- sapply(data, is.numeric)
data[numerical_columns] <- lapply(data[numerical_columns], function(x) ifelse(is.na(x), mean(x, na.rm = TRUE), x))

# 4. Remove Duplicate Entries
data <- distinct(data)

# 5. Data Type Conversion
# Ensure 'year' is an integer
data$year <- as.integer(data$year)

# Convert 'population' to numeric, handling any non-numeric entries
data$population <- as.numeric(data$population)

# 6. Handling Categorical Data (optional)
# If 'country' and 'iso_code' need encoding, you can use one-hot encoding
data <- data %>% mutate(country = factor(country))  # Convert country to factor for encoding if necessary
data <- cbind(data, model.matrix(~ country - 1, data))  # One-hot encoding for country (if needed)

# 7. Feature Scaling (standardization)
numerical_columns <- names(data)[sapply(data, is.numeric)]
data[numerical_columns] <- scale(data[numerical_columns])

# 8. Outlier Detection
# Example: Remove rows where 'co2' is above a certain threshold (adjust the threshold as needed)
data <- data %>% filter(co2 < 10000)

# 9. Create New Features (example: Year-over-year change in CO2)
data$co2_growth <- c(NA, diff(data$co2) / head(data$co2, -1))  # Year-over-year percentage growth

# 10. Interpolation for Time Series Data (Linear or Spline)
# Interpolate missing values in the 'co2' column using linear interpolation
data$co2 <- zoo(data$co2, order.by = data$year)
data$co2 <- na.approx(data$co2)  # Linear interpolation
# Alternatively, for spline interpolation, use this:
# data$co2 <- na.spline(data$co2)  # Uncomment for spline interpolation

# 11. Mode Imputation for Categorical Data
# Impute missing 'country' values with the mode
get_mode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

# Impute missing 'country' values with the mode
data$country[is.na(data$country)] <- get_mode(data$country)

# 12. Check for Multicollinearity (optional)
correlation_matrix <- cor(data[numerical_columns], use = "complete.obs")
print("Correlation Matrix:")
print(correlation_matrix)

# 13. Data Splitting (optional)
set.seed(42)
trainIndex <- createDataPartition(data$co2, p = 0.7, list = FALSE)  # 70% train, 30% test
train_data <- data[trainIndex, ]
test_data <- data[-trainIndex, ]

# Print the final preprocessed data
print("Preprocessed Data:")
print(head(data))



```

```{r}

```